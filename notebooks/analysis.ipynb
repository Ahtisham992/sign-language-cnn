{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Sign Language Digits Recognition Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook provides an interactive analysis of the sign language digits recognition project.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import sys\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"sys.path.append('../src')\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"from config import *\\n\",\n",
    "    \"from data_preprocessing import DataPreprocessor\\n\",\n",
    "    \"from model_training import ModelTrainer\\n\",\n",
    "    \"from evaluation import ModelEvaluator\\n\",\n",
    "    \"from hyperparameter_tuning import HyperparameterTuner\\n\",\n",
    "    \"from visualization import Visualizer\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8')\\n\",\n",
    "    \"plt.rcParams['figure.figsize'] = (12, 8)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"All imports successful!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Data Exploration and Preprocessing\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize preprocessor and visualizer\\n\",\n",
    "    \"preprocessor = DataPreprocessor()\\n\",\n",
    "    \"visualizer = Visualizer()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load dataset\\n\",\n",
    "    \"print(\\\"Loading dataset...\\\")\\n\",\n",
    "    \"if preprocessor.load_kaggle_dataset():\\n\",\n",
    "    \"    print(f\\\"Dataset loaded successfully!\\\")\\n\",\n",
    "    \"    print(f\\\"Total samples: {len(preprocessor.image_data)}\\\")\\n\",\n",
    "    \"    print(f\\\"Image shape: {preprocessor.image_data.shape}\\\")\\n\",\n",
    "    \"    print(f\\\"Labels shape: {preprocessor.labels.shape}\\\")\\nelse:\\n\",\n",
    "    \"    print(\\\"Failed to load dataset. Please check the data directory.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize sample images\\n\",\n",
    "    \"visualizer.plot_sample_images(\\n\",\n",
    "    \"    preprocessor.image_data,\\n\",\n",
    "    \"    preprocessor.labels\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Show class distribution\\n\",\n",
    "    \"distribution = visualizer.plot_data_distribution(preprocessor.labels)\\n\",\n",
    "    \"print(\\\"\\\\nClass distribution:\\\")\\n\",\n",
    "    \"for digit, count in distribution.items():\\n\",\n",
    "    \"    print(f\\\"  Digit {digit}: {count} samples\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Normalize and split data\\n\",\n",
    "    \"preprocessor.normalize_data('standard')\\n\",\n",
    "    \"preprocessor.split_data()\\n\",\n",
    "    \"preprocessor.save_processed_data()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Data preprocessing completed!\\\")\\n\",\n",
    "    \"print(f\\\"Training samples: {preprocessor.X_train.shape[0]}\\\")\\n\",\n",
    "    \"print(f\\\"Validation samples: {preprocessor.X_val.shape[0]}\\\")\\n\",\n",
    "    \"print(f\\\"Test samples: {preprocessor.X_test.shape[0]}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Model Training and Evaluation\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize trainer and evaluator\\n\",\n",
    "    \"trainer = ModelTrainer()\\n\",\n",
    "    \"evaluator = ModelEvaluator()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load preprocessed data\\n\",\n",
    "    \"trainer.load_data()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Train a basic model\\n\",\n",
    "    \"print(\\\"Training basic model...\\\")\\n\",\n",
    "    \"history = trainer.train_model(model_type='basic', epochs=20, use_augmentation=True)\\n\",\n",
    "    \"print(\\\"Training completed!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Plot training history\\n\",\n",
    "    \"trainer.plot_training_history()\\n\",\n",
    "    \"trainer.save_training_history()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Evaluate model\\n\",\n",
    "    \"eval_results = trainer.evaluate_model()\\n\",\n",
    "    \"metrics = evaluator.calculate_metrics(\\n\",\n",
    "    \"    eval_results['y_true_classes'],\\n\",\n",
    "    \"    eval_results['y_pred_classes'],\\n\",\n",
    "    \"    eval_results['y_pred']\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Test Accuracy: {metrics['accuracy']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Test Precision: {metrics['precision_macro']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Test Recall: {metrics['recall_macro']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Test F1-Score: {metrics['f1_macro']:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Generate evaluation plots\\n\",\n",
    "    \"evaluator.plot_confusion_matrix(\\n\",\n",
    "    \"    eval_results['y_true_classes'],\\n\",\n",
    "    \"    eval_results['y_pred_classes']\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# ROC curves\\n\",\n",
    "    \"evaluator.plot_roc_curves(\\n\",\n",
    "    \"    eval_results['y_true_classes'],\\n\",\n",
    "    \"    eval_results['y_pred']\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Precision-Recall curves\\n\",\n",
    "    \"evaluator.plot_precision_recall_curves(\\n\",\n",
    "    \"    eval_results['y_true_classes'],\\n\",\n",
    "    \"    eval_results['y_pred']\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Hyperparameter Tuning\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize hyperparameter tuner\\n\",\n",
    "    \"tuner = HyperparameterTuner()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Analyze batch size effect\\n\",\n",
    "    \"print(\\\"Analyzing batch size effect...\\\")\\n\",\n",
    "    \"batch_results = tuner.analyze_batch_size_effect()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Convert to DataFrame for visualization\\n\",\n",
    "    \"batch_df = pd.DataFrame(batch_results)\\n\",\n",
    "    \"print(batch_df)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize batch size analysis\\n\",\n",
    "    \"visualizer.plot_hyperparameter_analysis(batch_results, 'batch_size')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze learning rate effect\\n\",\n",
    "    \"print(\\\"Analyzing learning rate effect...\\\")\\n\",\n",
    "    \"lr_results = tuner.analyze_learning_rate_effect()\\n\",\n",
    "    \"visualizer.plot_hyperparameter_analysis(lr_results, 'learning_rate')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze regularization effect\\n\",\n",
    "    \"print(\\\"Analyzing regularization effect...\\\")\\n\",\n",
    "    \"reg_results = tuner.analyze_regularization_effect()\\n\",\n",
    "    \"visualizer.plot_regularization_comparison(reg_results)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Model Architecture Comparison\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Compare different model architectures\\n\",\n",
    "    \"print(\\\"Comparing model architectures...\\\")\\n\",\n",
    "    \"model_types = ['basic', 'advanced']\\n\",\n",
    "    \"arch_results = tuner.compare_models(model_types, epochs=10)  # Reduced epochs for notebook\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display results\\n\",\n",
    "    \"for model_type, result in arch_results.items():\\n\",\n",
    "    \"    print(f\\\"\\\\n{model_type.upper()} Model:\\\")\\n\",\n",
    "    \"    print(f\\\"  Test Accuracy: {result['metrics']['accuracy']:.4f}\\\")\\n\",\n",
    "    \"    print(f\\\"  Training Time: {result['training_time']:.2f} seconds\\\")\\n\",\n",
    "    \"    print(f\\\"  Final Val Accuracy: {result['final_val_accuracy']:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create comparison visualization\\n\",\n",
    "    \"comparison_df = evaluator.compare_models(arch_results)\\n\",\n",
    "    \"print(\\\"\\\\nModel Comparison Summary:\\\")\\n\",\n",
    "    \"print(comparison_df)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Results Dashboard\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create results dashboard\\n\",\n",
    "    \"dashboard_results = {}\\n\",\n",
    "    \"for model_type, result in arch_results.items():\\n\",\n",
    "    \"    dashboard_results[model_type] = {\\n\",\n",
    "    \"        'test_accuracy': result['metrics']['accuracy'],\\n\",\n",
    "    \"        'precision': result['metrics']['precision_macro'],\\n\",\n",
    "    \"        'recall': result['metrics']['recall_macro'],\\n\",\n",
    "    \"        'f1_score': result['metrics']['f1_macro'],\\n\",\n",
    "    \"        'training_time': result['training_time'],\\n\",\n",
    "    \"        'total_params': 100000,  # Placeholder\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"visualizer.create_results_dashboard(dashboard_results)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Error Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze misclassifications\\n\",\n",
    "    \"misclassified_pairs = evaluator.analyze_misclassifications(\\n\",\n",
    "    \"    trainer.preprocessor.X_test,\\n\",\n",
    "    \"    eval_results['y_true_classes'],\\n\",\n",
    "    \"    eval_results['y_pred_classes'],\\n\",\n",
    "    \"    eval_results['y_pred']\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Prediction confidence analysis\\n\",\n",
    "    \"evaluator.plot_prediction_confidence(\\n\",\n",
    "    \"    eval_results['y_pred'],\\n\",\n",
    "    \"    eval_results['y_true_classes']\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Summary and Conclusions\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Generate comprehensive evaluation report\\n\",\n",
    "    \"evaluator.generate_evaluation_report(\\n\",\n",
    "    \"    model_name=\\\"Final_CNN_Model\\\",\\n\",\n",
    "    \"    y_true=eval_results['y_true_classes'],\\n\",\n",
    "    \"    y_pred=eval_results['y_pred_classes'],\\n\",\n",
    "    \"    y_pred_proba=eval_results['y_pred'],\\n\",\n",
    "    \"    training_time=100.0  # Placeholder\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nAnalysis completed! Check the results directory for saved plots and reports.\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
