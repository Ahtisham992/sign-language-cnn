{
 "cells": [
  {
   "cell_type": "code",
   "id": "192de52fab0d8d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T10:18:47.024846Z",
     "start_time": "2025-09-16T10:18:46.427124Z"
    }
   },
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"notebook-intro\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Sign Language Digits Recognition Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook provides an interactive analysis of the sign language digits recognition project.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Setup Instructions:\\n\",\n",
    "    \"1. Ensure the dataset is placed in `data/raw/Dataset/` with folders 0/, 1/, 2/, ..., 9/\\n\",\n",
    "    \"2. Run cells sequentially\\n\",\n",
    "    \"3. Results will be saved in the `results/` directory\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"id\": \"imports-setup\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import all necessary libraries\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Suppress warnings for cleaner output\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add project directories to path\\n\",\n",
    "    \"sys.path.append('../src')\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Check if we can import the config\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    from config import *\\n\",\n",
    "    \"    print(\\\"✓ Config imported successfully\\\")\\n\",\n",
    "    \"except ImportError as e:\\n\",\n",
    "    \"    print(f\\\"❌ Config import failed: {e}\\\")\\n\",\n",
    "    \"    print(\\\"Creating basic config...\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Basic config if import fails\\n\",\n",
    "    \"    BASE_DIR = os.path.dirname(os.path.abspath('..'))\\n\",\n",
    "    \"    DATA_DIR = os.path.join(BASE_DIR, 'data')\\n\",\n",
    "    \"    RAW_DATA_DIR = os.path.join(DATA_DIR, 'raw')\\n\",\n",
    "    \"    PROCESSED_DATA_DIR = os.path.join(DATA_DIR, 'processed')\\n\",\n",
    "    \"    RESULTS_DIR = os.path.join(BASE_DIR, 'results')\\n\",\n",
    "    \"    PLOTS_DIR = os.path.join(RESULTS_DIR, 'plots')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    NUM_CLASSES = 10\\n\",\n",
    "    \"    IMAGE_SIZE = (64, 64)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create directories\\n\",\n",
    "    \"    for dir_path in [DATA_DIR, RAW_DATA_DIR, PROCESSED_DATA_DIR, RESULTS_DIR, PLOTS_DIR]:\\n\",\n",
    "    \"        os.makedirs(dir_path, exist_ok=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Import project modules\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    from src.data_preprocessing import DataPreprocessor\\n\",\n",
    "    \"    from src.model_training import ModelTrainer\\n\",\n",
    "    \"    from src.evaluation import ModelEvaluator\\n\",\n",
    "    \"    from src.hyperparameter_tuning import HyperparameterTuner\\n\",\n",
    "    \"    from src.visualization import Visualizer\\n\",\n",
    "    \"    print(\\\"✓ All project modules imported successfully\\\")\\n\",\n",
    "    \"except ImportError as e:\\n\",\n",
    "    \"    print(f\\\"❌ Module import failed: {e}\\\")\\n\",\n",
    "    \"    print(\\\"Please ensure you're running this notebook from the notebooks/ directory\\\")\\n\",\n",
    "    \"    print(\\\"and that all source files are in the src/ directory\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set plotting style\\n\",\n",
    "    \"plt.style.use('default')\\n\",\n",
    "    \"plt.rcParams['figure.figsize'] = (12, 8)\\n\",\n",
    "    \"plt.rcParams['font.size'] = 10\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*50)\\n\",\n",
    "    \"print(\\\"NOTEBOOK SETUP COMPLETED\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"data-exploration-header\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Data Exploration and Preprocessing\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"id\": \"data-loading\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize preprocessor and visualizer\\n\",\n",
    "    \"print(\\\"Initializing components...\\\")\\n\",\n",
    "    \"preprocessor = DataPreprocessor()\\n\",\n",
    "    \"visualizer = Visualizer()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Components initialized successfully!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"id\": \"dataset-inspection\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# First, let's inspect the dataset structure\\n\",\n",
    "    \"print(\\\"Inspecting dataset structure...\\\")\\n\",\n",
    "    \"preprocessor.inspect_dataset_structure()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*50)\\n\",\n",
    "    \"print(\\\"DATASET STRUCTURE INSPECTION COMPLETED\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"id\": \"dataset-loading\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load the dataset using the updated method\\n\",\n",
    "    \"print(\\\"Loading Sign Language Digits dataset...\\\")\\n\",\n",
    "    \"print(\\\"-\\\" * 40)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Try to load the dataset\\n\",\n",
    "    \"success = preprocessor.load_kaggle_dataset()\\n\",\n",
    "    \"\\n\",\n",
    "    \"if success:\\n\",\n",
    "    \"    print(\\\"\\\\n✓ Dataset loaded successfully!\\\")\\n\",\n",
    "    \"    print(f\\\"Total samples: {len(preprocessor.image_data)}\\\")\\n\",\n",
    "    \"    print(f\\\"Image shape: {preprocessor.image_data.shape}\\\")\\n\",\n",
    "    \"    print(f\\\"Labels shape: {preprocessor.labels.shape}\\\")\\n\",\n",
    "    \"    print(f\\\"Image data type: {preprocessor.image_data.dtype}\\\")\\n\",\n",
    "    \"    print(f\\\"Labels data type: {preprocessor.labels.dtype}\\\")\\n\",\n",
    "    \"    print(f\\\"Image value range: [{preprocessor.image_data.min()}, {preprocessor.image_data.max()}]\\\")\\n\",\n",
    "    \"    print(f\\\"Label range: [{preprocessor.labels.min()}, {preprocessor.labels.max()}]\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Verify data alignment\\n\",\n",
    "    \"    print(\\\"\\\\nVerifying data alignment...\\\")\\n\",\n",
    "    \"    alignment_ok = preprocessor.verify_data_alignment()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if alignment_ok:\\n\",\n",
    "    \"        print(\\\"✓ Data alignment verification passed!\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(\\\"❌ Data alignment issues detected!\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"\\\\n❌ Failed to load dataset!\\\")\\n\",\n",
    "    \"    print(\\\"\\\\nTroubleshooting steps:\\\")\\n\",\n",
    "    \"    print(\\\"1. Download dataset from: https://github.com/ardamavi/Sign-Language-Digits-Dataset\\\")\\n\",\n",
    "    \"    print(\\\"2. Extract and place 'Dataset' folder in data/raw/ directory\\\")\\n\",\n",
    "    \"    print(\\\"3. Ensure folder structure: data/raw/Dataset/0/, data/raw/Dataset/1/, ..., data/raw/Dataset/9/\\\")\\n\",\n",
    "    \"    print(\\\"4. Each digit folder should contain image files\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*50)\\n\",\n",
    "    \"print(\\\"DATASET LOADING COMPLETED\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"id\": \"sample-visualization\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize sample images from each class\\n\",\n",
    "    \"if preprocessor.image_data is not None:\\n\",\n",
    "    \"    print(\\\"Visualizing sample images...\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        visualizer.plot_sample_images(\\n\",\n",
    "    \"            preprocessor.image_data,\\n\",\n",
    "    \"            preprocessor.labels,\\n\",\n",
    "    \"            save_path=os.path.join(PLOTS_DIR, 'sample_images.png')\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        print(\\\"✓ Sample images visualization completed\\\")\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"❌ Sample visualization failed: {e}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Alternative visualization\\n\",\n",
    "    \"        print(\\\"Trying alternative visualization...\\\")\\n\",\n",
    "    \"        preprocessor.visualize_samples(save_path=os.path.join(PLOTS_DIR, 'sample_images_alt.png'))\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"❌ Cannot visualize - no data loaded\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"id\": \"class-distribution\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze class distribution\\n\",\n",
    "    \"if preprocessor.labels is not None:\\n\",\n",
    "    \"    print(\\\"Analyzing class distribution...\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        distribution = visualizer.plot_data_distribution(\\n\",\n",
    "    \"            preprocessor.labels,\\n\",\n",
    "    \"            save_path=os.path.join(PLOTS_DIR, 'class_distribution.png')\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(\\\"\\\\nClass distribution:\\\")\\n\",\n",
    "    \"        for digit, count in distribution.items():\\n\",\n",
    "    \"            percentage = (count / len(preprocessor.labels)) * 100\\n\",\n",
    "    \"            print(f\\\"  Digit {digit}: {count} samples ({percentage:.1f}%)\\\")\\n\",\n",
    "    \"            \\n\",\n",
    "    \"        print(\\\"✓ Class distribution analysis completed\\\")\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"❌ Distribution analysis failed: {e}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Alternative distribution analysis\\n\",\n",
    "    \"        print(\\\"Using alternative method...\\\")\\n\",\n",
    "    \"        distribution = preprocessor.get_class_distribution()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"❌ Cannot analyze distribution - no labels loaded\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"id\": \"data-preprocessing\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Normalize and split the data\\n\",\n",
    "    \"if preprocessor.image_data is not None:\\n\",\n",
    "    \"    print(\\\"Preprocessing data...\\\")\\n\",\n",
    "    \"    print(\\\"-\\\" * 30)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        # Normalize data to [0, 1] range\\n\",\n",
    "    \"        print(\\\"1. Normalizing data...\\\")\\n\",\n",
    "    \"        preprocessor.normalize_data('standard')\\n\",\n",
    "    \"        print(f\\\"   After normalization: [{preprocessor.image_data.min():.3f}, {preprocessor.image_data.max():.3f}]\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Split data into train/val/test\\n\",\n",
    "    \"        print(\\\"2. Splitting data...\\\")\\n\",\n",
    "    \"        preprocessor.split_data(test_size=0.15, val_size=0.15, random_state=42)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(f\\\"   Training samples: {preprocessor.X_train.shape[0]}\\\")\\n\",\n",
    "    \"        print(f\\\"   Validation samples: {preprocessor.X_val.shape[0]}\\\")\\n\",\n",
    "    \"        print(f\\\"   Test samples: {preprocessor.X_test.shape[0]}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Save processed data\\n\",\n",
    "    \"        print(\\\"3. Saving processed data...\\\")\\n\",\n",
    "    \"        preprocessor.save_processed_data()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(\\\"✓ Data preprocessing completed successfully!\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"❌ Data preprocessing failed: {e}\\\")\\n\",\n",
    "    \"        import traceback\\n\",\n",
    "    \"        traceback.print_exc()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"❌ Cannot preprocess - no data loaded\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*50)\\n\",\n",
    "    \"print(\\\"DATA PREPROCESSING COMPLETED\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"model-training-header\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Model Training and Evaluation\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"id\": \"trainer-initialization\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize trainer and evaluator\\n\",\n",
    "    \"print(\\\"Initializing model trainer and evaluator...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    trainer = ModelTrainer()\\n\",\n",
    "    \"    evaluator = ModelEvaluator()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Load preprocessed data\\n\",\n",
    "    \"    print(\\\"Loading preprocessed data...\\\")\\n\",\n",
    "    \"    data_loaded = trainer.load_data()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if data_loaded:\\n\",\n",
    "    \"        print(\\\"✓ Preprocessed data loaded successfully\\\")\\n\",\n",
    "    \"        print(f\\\"Training data shape: {trainer.preprocessor.X_train.shape}\\\")\\n\",\n",
    "    \"        print(f\\\"Validation data shape: {trainer.preprocessor.X_val.shape}\\\")\\n\",\n",
    "    \"        print(f\\\"Test data shape: {trainer.preprocessor.X_test.shape}\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(\\\"❌ Failed to load preprocessed data\\\")\\n\",\n",
    "    \"        print(\\\"Using data from current preprocessing...\\\")\\n\",\n",
    "    \"        trainer.preprocessor = preprocessor\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    print(\\\"✓ Trainer and evaluator initialized\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"except Exception as e:\\n\",\n",
    "    \"    print(f\\\"❌ Initialization failed: {e}\\\")\\n\",\n",
    "    \"    import traceback\\n\",\n",
    "    \"    traceback.print_exc()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"id\": \"model-training\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Train a basic CNN model\\n\",\n",
    "    \"print(\\\"Training CNN model...\\\")\\n\",\n",
    "    \"print(\\\"-\\\" * 30)\\n\",\n",
    "    \"\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    # Train model with data augmentation\\n\",\n",
    "    \"    print(\\\"Starting training...\\\")\\n\",\n",
    "    \"    history = trainer.train_model(\\n\",\n",
    "    \"        model_type='basic', \\n\",\n",
    "    \"        epochs=20, \\n\",\n",
    "    \"        batch_size=32,\\n\",\n",
    "    \"        use_augmentation=True,\\n\",\n",
    "    \"        verbose=1\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"✓ Model training completed!\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Display training summary\\n\",\n",
    "    \"    if history and hasattr(history, 'history'):\\n\",\n",
    "    \"        final_train_acc = history.history['accuracy'][-1]\\n\",\n",
    "    \"        final_val_acc = history.history['val_accuracy'][-1]\\n\",\n",
    "    \"        print(f\\\"Final training accuracy: {final_train_acc:.4f}\\\")\\n\",\n",
    "    \"        print(f\\\"Final validation accuracy: {final_val_acc:.4f}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"except Exception as e:\\n\",\n",
    "    \"    print(f\\\"❌ Training failed: {e}\\\")\\n\",\n",
    "    \"    import traceback\\n\",\n",
    "    \"    traceback.print_exc()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*50)\\n\",\n",
    "    \"print(\\\"MODEL TRAINING COMPLETED\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"id\": \"training-visualization\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Plot training history\\n\",\n",
    "    \"if 'history' in locals() and history is not None:\\n\",\n",
    "    \"    print(\\\"Visualizing training history...\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        trainer.plot_training_history(\\n\",\n",
    "    \"            save_path=os.path.join(PLOTS_DIR, 'training_history.png')\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Also save training history data\\n\",\n",
    "    \"        trainer.save_training_history()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(\\\"✓ Training history visualization completed\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"❌ History visualization failed: {e}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Alternative visualization\\n\",\n",
    "    \"        print(\\\"Creating alternative training plots...\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Plot accuracy\\n\",\n",
    "    \"        ax1.plot(history.history['accuracy'], label='Training Accuracy')\\n\",\n",
    "    \"        ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\\n\",\n",
    "    \"        ax1.set_title('Model Accuracy')\\n\",\n",
    "    \"        ax1.set_xlabel('Epoch')\\n\",\n",
    "    \"        ax1.set_ylabel('Accuracy')\\n\",\n",
    "    \"        ax1.legend()\\n\",\n",
    "    \"        ax1.grid(True)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Plot loss\\n\",\n",
    "    \"        ax2.plot(history.history['loss'], label='Training Loss')\\n\",\n",
    "    \"        ax2.plot(history.history['val_loss'], label='Validation Loss')\\n\",\n",
    "    \"        ax2.set_title('Model Loss')\\n\",\n",
    "    \"        ax2.set_xlabel('Epoch')\\n\",\n",
    "    \"        ax2.set_ylabel('Loss')\\n\",\n",
    "    \"        ax2.legend()\\n\",\n",
    "    \"        ax2.grid(True)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        plt.tight_layout()\\n\",\n",
    "    \"        plt.savefig(os.path.join(PLOTS_DIR, 'training_history_alt.png'), dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"        plt.show()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"❌ No training history to visualize\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"id\": \"model-evaluation\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Evaluate the trained model\\n\",\n",
    "    \"print(\\\"Evaluating model performance...\\\")\\n\",\n",
    "    \"print(\\\"-\\\" * 35)\\n\",\n",
    "    \"\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    # Get evaluation results\\n\",\n",
    "    \"    eval_results = trainer.evaluate_model()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if eval_results:\\n\",\n",
    "    \"        # Calculate comprehensive metrics\\n\",\n",
    "    \"        metrics = evaluator.calculate_metrics(\\n\",\n",
    "    \"            eval_results['y_true_classes'],\\n\",\n",
    "    \"            eval_results['y_pred_classes'],\\n\",\n",
    "    \"            eval_results['y_pred']\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Display key metrics\\n\",\n",
    "    \"        print(\\\"\\\\n📊 Model Performance Metrics:\\\")\\n\",\n",
    "    \"        print(f\\\"Test Accuracy:  {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)\\\")\\n\",\n",
    "    \"        print(f\\\"Precision (macro): {metrics['precision_macro']:.4f}\\\")\\n\",\n",
    "    \"        print(f\\\"Recall (macro):    {metrics['recall_macro']:.4f}\\\")\\n\",\n",
    "    \"        print(f\\\"F1-Score (macro):  {metrics['f1_macro']:.4f}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(\\\"\\\\n✓ Model evaluation completed successfully!\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(\\\"❌ Model evaluation failed - no results returned\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"except Exception as e:\\n\",\n",
    "    \"    print(f\\\"❌ Evaluation failed: {e}\\\")\\n\",\n",
    "    \"    import traceback\\n\",\n",
    "    \"    traceback.print_exc()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"id\": \"confusion-matrix\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Generate confusion matrix\\n\",\n",
    "    \"if 'eval_results' in locals() and eval_results is not None:\\n\",\n",
    "    \"    print(\\\"Generating confusion matrix...\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        evaluator.plot_confusion_matrix(\\n\",\n",
    "    \"            eval_results['y_true_classes'],\\n\",\n",
    "    \"            eval_results['y_pred_classes'],\\n\",\n",
    "    \"            save_path=os.path.join(PLOTS_DIR, 'confusion_matrix.png')\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        print(\\\"✓ Confusion matrix generated\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"❌ Confusion matrix generation failed: {e}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Alternative confusion matrix\\n\",\n",
    "    \"        from sklearn.metrics import confusion_matrix\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        cm = confusion_matrix(eval_results['y_true_classes'], eval_results['y_pred_classes'])\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        plt.figure(figsize=(10, 8))\\n\",\n",
    "    \"        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \\n\",\n",
    "    \"                   xticklabels=range(10), yticklabels=range(10))\\n\",\n",
    "    \"        plt.title('Confusion Matrix')\\n\",\n",
    "    \"        plt.xlabel('Predicted Label')\\n\",\n",
    "    \"        plt.ylabel('True Label')\\n\",\n",
    "    \"        plt.savefig(os.path.join(PLOTS_DIR, 'confusion_matrix_alt.png'), dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"        plt.show()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"❌ Cannot generate confusion matrix - no evaluation results\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"id\": \"roc-curves\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Generate ROC curves\\n\",\n",
    "    \"if 'eval_results' in locals() and eval_results is not None:\\n\",\n",
    "    \"    print(\\\"Generating ROC curves...\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        evaluator.plot_roc_curves(\\n\",\n",
    "    \"            eval_results['y_true_classes'],\\n\",\n",
    "    \"            eval_results['y_pred'],\\n\",\n",
    "    \"            save_path=os.path.join(PLOTS_DIR, 'roc_curves.png')\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        print(\\\"✓ ROC curves generated\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"❌ ROC curves generation failed: {e}\\\")\\n\",\n",
    "    \"        import traceback\\n\",\n",
    "    \"        traceback.print_exc()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"❌ Cannot generate ROC curves - no evaluation results\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"id\": \"precision-recall-curves\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Generate Precision-Recall curves\\n\",\n",
    "    \"if 'eval_results' in locals() and eval_results is not None:\\n\",\n",
    "    \"    print(\\\"Generating Precision-Recall curves...\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        evaluator.plot_precision_recall_curves(\\n\",\n",
    "    \"            eval_results['y_true_classes'],\\n\",\n",
    "    \"            eval_results['y_pred'],\\n\",\n",
    "    \"            save_path=os.path.join(PLOTS_DIR, 'precision_recall_curves.png')\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        print(\\\"✓ Precision-Recall curves generated\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"❌ Precision-Recall curves generation failed: {e}\\\")\\n\",\n",
    "    \"        import traceback\\n\",\n",
    "    \"        traceback.print_exc()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"❌ Cannot generate Precision-Recall curves - no evaluation results\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"hyperparameter-tuning-header\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Hyperparameter Tuning Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"id\": \"hyperparameter-tuner-init\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize hyperparameter tuner\\n\",\n",
    "    \"print(\\\"Initializing hyperparameter tuner...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    tuner = HyperparameterTuner()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Load data for tuning\\n\",\n",
    "    \"    if not tuner.trainer.load_data():\\n\",\n",
    "    \"        print(\\\"Using current preprocessor data...\\\")\\n\",\n",
    "    \"        tuner.trainer.preprocessor = preprocessor\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"✓ Hyperparameter tuner initialized\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"except Exception as e:\\n\",\n",
    "    \"    print(f\\\"❌ Tuner initialization failed: {e}\\\")\\n\",\n",
    "    \"    import traceback\\n\",\n",
    "    \"    traceback.print_exc()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"id\": \"batch-size-analysis\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze batch size effect (with reduced epochs for notebook)\\n\",\n",
    "    \"if 'tuner' in locals():\\n\",\n",
    "    \"    print(\\\"Analyzing batch size effect...\\\")\\n\",\n",
    "    \"    print(\\\"(Using reduced epochs for notebook demonstration)\\\")\\n\",\n",
    "    \"    print(\\\"-\\\" * 45)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        # Temporarily modify epochs for faster notebook execution\\n\",\n",
    "    \"        original_epochs = tuner.trainer.epochs if hasattr(tuner.trainer, 'epochs') else 10\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        batch_results = tuner.analyze_batch_size_effect(\\n\",\n",
    "    \"            batch_sizes=[16, 32, 64], \\n\",\n",
    "    \"            epochs=5  # Reduced for notebook\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if batch_results:\\n\",\n",
    "    \"            # Convert to DataFrame for better visualization\\n\",\n",
    "    \"            batch_df = pd.DataFrame(batch_results)\\n\",\n",
    "    \"            print(\\\"\\\\nBatch Size Analysis Results:\\\")\\n\",\n",
    "    \"            print(batch_df[['batch_size', 'final_val_accuracy', 'training_time']].round(4))\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Visualize results\\n\",\n",
    "    \"            try:\\n\",\n",
    "    \"                visualizer.plot_hyperparameter_analysis(\\n\",\n",
    "    \"                    batch_results, \\n\",\n",
    "    \"                    'batch_size',\\n\",\n",
    "    \"                    save_path=os.path.join(PLOTS_DIR, 'batch_size_analysis.png')\\n\",\n",
    "    \"                )\\n\",\n",
    "    \"                print(\\\"✓ Batch size analysis visualization completed\\\")\\n\",\n",
    "    \"            except Exception as viz_e:\\n\",\n",
    "    \"                print(f\\\"Visualization failed: {viz_e}\\\")\\n\",\n",
    "    \"                \\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            print(\\\"❌ Batch size analysis returned no results\\\")\\n\",\n",
    "    \"            \\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"❌ Batch size analysis failed: {e}\\\")\\n\",\n",
    "    \"        import traceback\\n\",\n",
    "    \"        traceback.print_exc()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"❌ Cannot run batch size analysis - tuner not initialized\\\")\"\n",
    "\n",
    "   ]\n",
    "  }]}"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': [{'cell_type': 'markdown',\n",
       "   'id': 'notebook-intro',\n",
       "   'metadata': {},\n",
       "   'source': ['# Sign Language Digits Recognition Analysis\\n',\n",
       "    '\\n',\n",
       "    'This notebook provides an interactive analysis of the sign language digits recognition project.\\n',\n",
       "    '\\n',\n",
       "    '## Setup Instructions:\\n',\n",
       "    '1. Ensure the dataset is placed in `data/raw/Dataset/` with folders 0/, 1/, 2/, ..., 9/\\n',\n",
       "    '2. Run cells sequentially\\n',\n",
       "    '3. Results will be saved in the `results/` directory']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'id': 'imports-setup',\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Import all necessary libraries\\n',\n",
       "    'import sys\\n',\n",
       "    'import os\\n',\n",
       "    'import numpy as np\\n',\n",
       "    'import pandas as pd\\n',\n",
       "    'import matplotlib.pyplot as plt\\n',\n",
       "    'import seaborn as sns\\n',\n",
       "    'import warnings\\n',\n",
       "    '\\n',\n",
       "    '# Suppress warnings for cleaner output\\n',\n",
       "    \"warnings.filterwarnings('ignore')\\n\",\n",
       "    '\\n',\n",
       "    '# Add project directories to path\\n',\n",
       "    \"sys.path.append('../src')\\n\",\n",
       "    \"sys.path.append('..')\\n\",\n",
       "    '\\n',\n",
       "    '# Check if we can import the config\\n',\n",
       "    'try:\\n',\n",
       "    '    from config import *\\n',\n",
       "    '    print(\"✓ Config imported successfully\")\\n',\n",
       "    'except ImportError as e:\\n',\n",
       "    '    print(f\"❌ Config import failed: {e}\")\\n',\n",
       "    '    print(\"Creating basic config...\")\\n',\n",
       "    '    \\n',\n",
       "    '    # Basic config if import fails\\n',\n",
       "    \"    BASE_DIR = os.path.dirname(os.path.abspath('..'))\\n\",\n",
       "    \"    DATA_DIR = os.path.join(BASE_DIR, 'data')\\n\",\n",
       "    \"    RAW_DATA_DIR = os.path.join(DATA_DIR, 'raw')\\n\",\n",
       "    \"    PROCESSED_DATA_DIR = os.path.join(DATA_DIR, 'processed')\\n\",\n",
       "    \"    RESULTS_DIR = os.path.join(BASE_DIR, 'results')\\n\",\n",
       "    \"    PLOTS_DIR = os.path.join(RESULTS_DIR, 'plots')\\n\",\n",
       "    '    \\n',\n",
       "    '    NUM_CLASSES = 10\\n',\n",
       "    '    IMAGE_SIZE = (64, 64)\\n',\n",
       "    '    \\n',\n",
       "    '    # Create directories\\n',\n",
       "    '    for dir_path in [DATA_DIR, RAW_DATA_DIR, PROCESSED_DATA_DIR, RESULTS_DIR, PLOTS_DIR]:\\n',\n",
       "    '        os.makedirs(dir_path, exist_ok=True)\\n',\n",
       "    '\\n',\n",
       "    '# Import project modules\\n',\n",
       "    'try:\\n',\n",
       "    '    from src.data_preprocessing import DataPreprocessor\\n',\n",
       "    '    from src.model_training import ModelTrainer\\n',\n",
       "    '    from src.evaluation import ModelEvaluator\\n',\n",
       "    '    from src.hyperparameter_tuning import HyperparameterTuner\\n',\n",
       "    '    from src.visualization import Visualizer\\n',\n",
       "    '    print(\"✓ All project modules imported successfully\")\\n',\n",
       "    'except ImportError as e:\\n',\n",
       "    '    print(f\"❌ Module import failed: {e}\")\\n',\n",
       "    '    print(\"Please ensure you\\'re running this notebook from the notebooks/ directory\")\\n',\n",
       "    '    print(\"and that all source files are in the src/ directory\")\\n',\n",
       "    '\\n',\n",
       "    '# Set plotting style\\n',\n",
       "    \"plt.style.use('default')\\n\",\n",
       "    \"plt.rcParams['figure.figsize'] = (12, 8)\\n\",\n",
       "    \"plt.rcParams['font.size'] = 10\\n\",\n",
       "    '\\n',\n",
       "    'print(\"\\\\n\" + \"=\"*50)\\n',\n",
       "    'print(\"NOTEBOOK SETUP COMPLETED\")\\n',\n",
       "    'print(\"=\"*50)']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'id': 'data-exploration-header',\n",
       "   'metadata': {},\n",
       "   'source': ['## 1. Data Exploration and Preprocessing']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'id': 'data-loading',\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Initialize preprocessor and visualizer\\n',\n",
       "    'print(\"Initializing components...\")\\n',\n",
       "    'preprocessor = DataPreprocessor()\\n',\n",
       "    'visualizer = Visualizer()\\n',\n",
       "    '\\n',\n",
       "    'print(\"Components initialized successfully!\")']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'id': 'dataset-inspection',\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': [\"# First, let's inspect the dataset structure\\n\",\n",
       "    'print(\"Inspecting dataset structure...\")\\n',\n",
       "    'preprocessor.inspect_dataset_structure()\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\n\" + \"=\"*50)\\n',\n",
       "    'print(\"DATASET STRUCTURE INSPECTION COMPLETED\")\\n',\n",
       "    'print(\"=\"*50)']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'id': 'dataset-loading',\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Load the dataset using the updated method\\n',\n",
       "    'print(\"Loading Sign Language Digits dataset...\")\\n',\n",
       "    'print(\"-\" * 40)\\n',\n",
       "    '\\n',\n",
       "    '# Try to load the dataset\\n',\n",
       "    'success = preprocessor.load_kaggle_dataset()\\n',\n",
       "    '\\n',\n",
       "    'if success:\\n',\n",
       "    '    print(\"\\\\n✓ Dataset loaded successfully!\")\\n',\n",
       "    '    print(f\"Total samples: {len(preprocessor.image_data)}\")\\n',\n",
       "    '    print(f\"Image shape: {preprocessor.image_data.shape}\")\\n',\n",
       "    '    print(f\"Labels shape: {preprocessor.labels.shape}\")\\n',\n",
       "    '    print(f\"Image data type: {preprocessor.image_data.dtype}\")\\n',\n",
       "    '    print(f\"Labels data type: {preprocessor.labels.dtype}\")\\n',\n",
       "    '    print(f\"Image value range: [{preprocessor.image_data.min()}, {preprocessor.image_data.max()}]\")\\n',\n",
       "    '    print(f\"Label range: [{preprocessor.labels.min()}, {preprocessor.labels.max()}]\")\\n',\n",
       "    '    \\n',\n",
       "    '    # Verify data alignment\\n',\n",
       "    '    print(\"\\\\nVerifying data alignment...\")\\n',\n",
       "    '    alignment_ok = preprocessor.verify_data_alignment()\\n',\n",
       "    '    \\n',\n",
       "    '    if alignment_ok:\\n',\n",
       "    '        print(\"✓ Data alignment verification passed!\")\\n',\n",
       "    '    else:\\n',\n",
       "    '        print(\"❌ Data alignment issues detected!\")\\n',\n",
       "    'else:\\n',\n",
       "    '    print(\"\\\\n❌ Failed to load dataset!\")\\n',\n",
       "    '    print(\"\\\\nTroubleshooting steps:\")\\n',\n",
       "    '    print(\"1. Download dataset from: https://github.com/ardamavi/Sign-Language-Digits-Dataset\")\\n',\n",
       "    '    print(\"2. Extract and place \\'Dataset\\' folder in data/raw/ directory\")\\n',\n",
       "    '    print(\"3. Ensure folder structure: data/raw/Dataset/0/, data/raw/Dataset/1/, ..., data/raw/Dataset/9/\")\\n',\n",
       "    '    print(\"4. Each digit folder should contain image files\")\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\n\" + \"=\"*50)\\n',\n",
       "    'print(\"DATASET LOADING COMPLETED\")\\n',\n",
       "    'print(\"=\"*50)']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'id': 'sample-visualization',\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Visualize sample images from each class\\n',\n",
       "    'if preprocessor.image_data is not None:\\n',\n",
       "    '    print(\"Visualizing sample images...\")\\n',\n",
       "    '    \\n',\n",
       "    '    try:\\n',\n",
       "    '        visualizer.plot_sample_images(\\n',\n",
       "    '            preprocessor.image_data,\\n',\n",
       "    '            preprocessor.labels,\\n',\n",
       "    \"            save_path=os.path.join(PLOTS_DIR, 'sample_images.png')\\n\",\n",
       "    '        )\\n',\n",
       "    '        print(\"✓ Sample images visualization completed\")\\n',\n",
       "    '    except Exception as e:\\n',\n",
       "    '        print(f\"❌ Sample visualization failed: {e}\")\\n',\n",
       "    '        \\n',\n",
       "    '        # Alternative visualization\\n',\n",
       "    '        print(\"Trying alternative visualization...\")\\n',\n",
       "    \"        preprocessor.visualize_samples(save_path=os.path.join(PLOTS_DIR, 'sample_images_alt.png'))\\n\",\n",
       "    'else:\\n',\n",
       "    '    print(\"❌ Cannot visualize - no data loaded\")']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'id': 'class-distribution',\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Analyze class distribution\\n',\n",
       "    'if preprocessor.labels is not None:\\n',\n",
       "    '    print(\"Analyzing class distribution...\")\\n',\n",
       "    '    \\n',\n",
       "    '    try:\\n',\n",
       "    '        distribution = visualizer.plot_data_distribution(\\n',\n",
       "    '            preprocessor.labels,\\n',\n",
       "    \"            save_path=os.path.join(PLOTS_DIR, 'class_distribution.png')\\n\",\n",
       "    '        )\\n',\n",
       "    '        \\n',\n",
       "    '        print(\"\\\\nClass distribution:\")\\n',\n",
       "    '        for digit, count in distribution.items():\\n',\n",
       "    '            percentage = (count / len(preprocessor.labels)) * 100\\n',\n",
       "    '            print(f\"  Digit {digit}: {count} samples ({percentage:.1f}%)\")\\n',\n",
       "    '            \\n',\n",
       "    '        print(\"✓ Class distribution analysis completed\")\\n',\n",
       "    '    except Exception as e:\\n',\n",
       "    '        print(f\"❌ Distribution analysis failed: {e}\")\\n',\n",
       "    '        \\n',\n",
       "    '        # Alternative distribution analysis\\n',\n",
       "    '        print(\"Using alternative method...\")\\n',\n",
       "    '        distribution = preprocessor.get_class_distribution()\\n',\n",
       "    'else:\\n',\n",
       "    '    print(\"❌ Cannot analyze distribution - no labels loaded\")']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'id': 'data-preprocessing',\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Normalize and split the data\\n',\n",
       "    'if preprocessor.image_data is not None:\\n',\n",
       "    '    print(\"Preprocessing data...\")\\n',\n",
       "    '    print(\"-\" * 30)\\n',\n",
       "    '    \\n',\n",
       "    '    try:\\n',\n",
       "    '        # Normalize data to [0, 1] range\\n',\n",
       "    '        print(\"1. Normalizing data...\")\\n',\n",
       "    \"        preprocessor.normalize_data('standard')\\n\",\n",
       "    '        print(f\"   After normalization: [{preprocessor.image_data.min():.3f}, {preprocessor.image_data.max():.3f}]\")\\n',\n",
       "    '        \\n',\n",
       "    '        # Split data into train/val/test\\n',\n",
       "    '        print(\"2. Splitting data...\")\\n',\n",
       "    '        preprocessor.split_data(test_size=0.15, val_size=0.15, random_state=42)\\n',\n",
       "    '        \\n',\n",
       "    '        print(f\"   Training samples: {preprocessor.X_train.shape[0]}\")\\n',\n",
       "    '        print(f\"   Validation samples: {preprocessor.X_val.shape[0]}\")\\n',\n",
       "    '        print(f\"   Test samples: {preprocessor.X_test.shape[0]}\")\\n',\n",
       "    '        \\n',\n",
       "    '        # Save processed data\\n',\n",
       "    '        print(\"3. Saving processed data...\")\\n',\n",
       "    '        preprocessor.save_processed_data()\\n',\n",
       "    '        \\n',\n",
       "    '        print(\"✓ Data preprocessing completed successfully!\")\\n',\n",
       "    '        \\n',\n",
       "    '    except Exception as e:\\n',\n",
       "    '        print(f\"❌ Data preprocessing failed: {e}\")\\n',\n",
       "    '        import traceback\\n',\n",
       "    '        traceback.print_exc()\\n',\n",
       "    'else:\\n',\n",
       "    '    print(\"❌ Cannot preprocess - no data loaded\")\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\n\" + \"=\"*50)\\n',\n",
       "    'print(\"DATA PREPROCESSING COMPLETED\")\\n',\n",
       "    'print(\"=\"*50)']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'id': 'model-training-header',\n",
       "   'metadata': {},\n",
       "   'source': ['## 2. Model Training and Evaluation']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'id': 'trainer-initialization',\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Initialize trainer and evaluator\\n',\n",
       "    'print(\"Initializing model trainer and evaluator...\")\\n',\n",
       "    '\\n',\n",
       "    'try:\\n',\n",
       "    '    trainer = ModelTrainer()\\n',\n",
       "    '    evaluator = ModelEvaluator()\\n',\n",
       "    '    \\n',\n",
       "    '    # Load preprocessed data\\n',\n",
       "    '    print(\"Loading preprocessed data...\")\\n',\n",
       "    '    data_loaded = trainer.load_data()\\n',\n",
       "    '    \\n',\n",
       "    '    if data_loaded:\\n',\n",
       "    '        print(\"✓ Preprocessed data loaded successfully\")\\n',\n",
       "    '        print(f\"Training data shape: {trainer.preprocessor.X_train.shape}\")\\n',\n",
       "    '        print(f\"Validation data shape: {trainer.preprocessor.X_val.shape}\")\\n',\n",
       "    '        print(f\"Test data shape: {trainer.preprocessor.X_test.shape}\")\\n',\n",
       "    '    else:\\n',\n",
       "    '        print(\"❌ Failed to load preprocessed data\")\\n',\n",
       "    '        print(\"Using data from current preprocessing...\")\\n',\n",
       "    '        trainer.preprocessor = preprocessor\\n',\n",
       "    '        \\n',\n",
       "    '    print(\"✓ Trainer and evaluator initialized\")\\n',\n",
       "    '    \\n',\n",
       "    'except Exception as e:\\n',\n",
       "    '    print(f\"❌ Initialization failed: {e}\")\\n',\n",
       "    '    import traceback\\n',\n",
       "    '    traceback.print_exc()']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'id': 'model-training',\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Train a basic CNN model\\n',\n",
       "    'print(\"Training CNN model...\")\\n',\n",
       "    'print(\"-\" * 30)\\n',\n",
       "    '\\n',\n",
       "    'try:\\n',\n",
       "    '    # Train model with data augmentation\\n',\n",
       "    '    print(\"Starting training...\")\\n',\n",
       "    '    history = trainer.train_model(\\n',\n",
       "    \"        model_type='basic', \\n\",\n",
       "    '        epochs=20, \\n',\n",
       "    '        batch_size=32,\\n',\n",
       "    '        use_augmentation=True,\\n',\n",
       "    '        verbose=1\\n',\n",
       "    '    )\\n',\n",
       "    '    \\n',\n",
       "    '    print(\"✓ Model training completed!\")\\n',\n",
       "    '    \\n',\n",
       "    '    # Display training summary\\n',\n",
       "    \"    if history and hasattr(history, 'history'):\\n\",\n",
       "    \"        final_train_acc = history.history['accuracy'][-1]\\n\",\n",
       "    \"        final_val_acc = history.history['val_accuracy'][-1]\\n\",\n",
       "    '        print(f\"Final training accuracy: {final_train_acc:.4f}\")\\n',\n",
       "    '        print(f\"Final validation accuracy: {final_val_acc:.4f}\")\\n',\n",
       "    '        \\n',\n",
       "    'except Exception as e:\\n',\n",
       "    '    print(f\"❌ Training failed: {e}\")\\n',\n",
       "    '    import traceback\\n',\n",
       "    '    traceback.print_exc()\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\n\" + \"=\"*50)\\n',\n",
       "    'print(\"MODEL TRAINING COMPLETED\")\\n',\n",
       "    'print(\"=\"*50)']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'id': 'training-visualization',\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Plot training history\\n',\n",
       "    \"if 'history' in locals() and history is not None:\\n\",\n",
       "    '    print(\"Visualizing training history...\")\\n',\n",
       "    '    \\n',\n",
       "    '    try:\\n',\n",
       "    '        trainer.plot_training_history(\\n',\n",
       "    \"            save_path=os.path.join(PLOTS_DIR, 'training_history.png')\\n\",\n",
       "    '        )\\n',\n",
       "    '        \\n',\n",
       "    '        # Also save training history data\\n',\n",
       "    '        trainer.save_training_history()\\n',\n",
       "    '        \\n',\n",
       "    '        print(\"✓ Training history visualization completed\")\\n',\n",
       "    '        \\n',\n",
       "    '    except Exception as e:\\n',\n",
       "    '        print(f\"❌ History visualization failed: {e}\")\\n',\n",
       "    '        \\n',\n",
       "    '        # Alternative visualization\\n',\n",
       "    '        print(\"Creating alternative training plots...\")\\n',\n",
       "    '        \\n',\n",
       "    '        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\\n',\n",
       "    '        \\n',\n",
       "    '        # Plot accuracy\\n',\n",
       "    \"        ax1.plot(history.history['accuracy'], label='Training Accuracy')\\n\",\n",
       "    \"        ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\\n\",\n",
       "    \"        ax1.set_title('Model Accuracy')\\n\",\n",
       "    \"        ax1.set_xlabel('Epoch')\\n\",\n",
       "    \"        ax1.set_ylabel('Accuracy')\\n\",\n",
       "    '        ax1.legend()\\n',\n",
       "    '        ax1.grid(True)\\n',\n",
       "    '        \\n',\n",
       "    '        # Plot loss\\n',\n",
       "    \"        ax2.plot(history.history['loss'], label='Training Loss')\\n\",\n",
       "    \"        ax2.plot(history.history['val_loss'], label='Validation Loss')\\n\",\n",
       "    \"        ax2.set_title('Model Loss')\\n\",\n",
       "    \"        ax2.set_xlabel('Epoch')\\n\",\n",
       "    \"        ax2.set_ylabel('Loss')\\n\",\n",
       "    '        ax2.legend()\\n',\n",
       "    '        ax2.grid(True)\\n',\n",
       "    '        \\n',\n",
       "    '        plt.tight_layout()\\n',\n",
       "    \"        plt.savefig(os.path.join(PLOTS_DIR, 'training_history_alt.png'), dpi=300, bbox_inches='tight')\\n\",\n",
       "    '        plt.show()\\n',\n",
       "    'else:\\n',\n",
       "    '    print(\"❌ No training history to visualize\")']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'id': 'model-evaluation',\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Evaluate the trained model\\n',\n",
       "    'print(\"Evaluating model performance...\")\\n',\n",
       "    'print(\"-\" * 35)\\n',\n",
       "    '\\n',\n",
       "    'try:\\n',\n",
       "    '    # Get evaluation results\\n',\n",
       "    '    eval_results = trainer.evaluate_model()\\n',\n",
       "    '    \\n',\n",
       "    '    if eval_results:\\n',\n",
       "    '        # Calculate comprehensive metrics\\n',\n",
       "    '        metrics = evaluator.calculate_metrics(\\n',\n",
       "    \"            eval_results['y_true_classes'],\\n\",\n",
       "    \"            eval_results['y_pred_classes'],\\n\",\n",
       "    \"            eval_results['y_pred']\\n\",\n",
       "    '        )\\n',\n",
       "    '        \\n',\n",
       "    '        # Display key metrics\\n',\n",
       "    '        print(\"\\\\n📊 Model Performance Metrics:\")\\n',\n",
       "    '        print(f\"Test Accuracy:  {metrics[\\'accuracy\\']:.4f} ({metrics[\\'accuracy\\']*100:.2f}%)\")\\n',\n",
       "    '        print(f\"Precision (macro): {metrics[\\'precision_macro\\']:.4f}\")\\n',\n",
       "    '        print(f\"Recall (macro):    {metrics[\\'recall_macro\\']:.4f}\")\\n',\n",
       "    '        print(f\"F1-Score (macro):  {metrics[\\'f1_macro\\']:.4f}\")\\n',\n",
       "    '        \\n',\n",
       "    '        print(\"\\\\n✓ Model evaluation completed successfully!\")\\n',\n",
       "    '        \\n',\n",
       "    '    else:\\n',\n",
       "    '        print(\"❌ Model evaluation failed - no results returned\")\\n',\n",
       "    '        \\n',\n",
       "    'except Exception as e:\\n',\n",
       "    '    print(f\"❌ Evaluation failed: {e}\")\\n',\n",
       "    '    import traceback\\n',\n",
       "    '    traceback.print_exc()']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'id': 'confusion-matrix',\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Generate confusion matrix\\n',\n",
       "    \"if 'eval_results' in locals() and eval_results is not None:\\n\",\n",
       "    '    print(\"Generating confusion matrix...\")\\n',\n",
       "    '    \\n',\n",
       "    '    try:\\n',\n",
       "    '        evaluator.plot_confusion_matrix(\\n',\n",
       "    \"            eval_results['y_true_classes'],\\n\",\n",
       "    \"            eval_results['y_pred_classes'],\\n\",\n",
       "    \"            save_path=os.path.join(PLOTS_DIR, 'confusion_matrix.png')\\n\",\n",
       "    '        )\\n',\n",
       "    '        print(\"✓ Confusion matrix generated\")\\n',\n",
       "    '        \\n',\n",
       "    '    except Exception as e:\\n',\n",
       "    '        print(f\"❌ Confusion matrix generation failed: {e}\")\\n',\n",
       "    '        \\n',\n",
       "    '        # Alternative confusion matrix\\n',\n",
       "    '        from sklearn.metrics import confusion_matrix\\n',\n",
       "    '        \\n',\n",
       "    \"        cm = confusion_matrix(eval_results['y_true_classes'], eval_results['y_pred_classes'])\\n\",\n",
       "    '        \\n',\n",
       "    '        plt.figure(figsize=(10, 8))\\n',\n",
       "    \"        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \\n\",\n",
       "    '                   xticklabels=range(10), yticklabels=range(10))\\n',\n",
       "    \"        plt.title('Confusion Matrix')\\n\",\n",
       "    \"        plt.xlabel('Predicted Label')\\n\",\n",
       "    \"        plt.ylabel('True Label')\\n\",\n",
       "    \"        plt.savefig(os.path.join(PLOTS_DIR, 'confusion_matrix_alt.png'), dpi=300, bbox_inches='tight')\\n\",\n",
       "    '        plt.show()\\n',\n",
       "    'else:\\n',\n",
       "    '    print(\"❌ Cannot generate confusion matrix - no evaluation results\")']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'id': 'roc-curves',\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Generate ROC curves\\n',\n",
       "    \"if 'eval_results' in locals() and eval_results is not None:\\n\",\n",
       "    '    print(\"Generating ROC curves...\")\\n',\n",
       "    '    \\n',\n",
       "    '    try:\\n',\n",
       "    '        evaluator.plot_roc_curves(\\n',\n",
       "    \"            eval_results['y_true_classes'],\\n\",\n",
       "    \"            eval_results['y_pred'],\\n\",\n",
       "    \"            save_path=os.path.join(PLOTS_DIR, 'roc_curves.png')\\n\",\n",
       "    '        )\\n',\n",
       "    '        print(\"✓ ROC curves generated\")\\n',\n",
       "    '        \\n',\n",
       "    '    except Exception as e:\\n',\n",
       "    '        print(f\"❌ ROC curves generation failed: {e}\")\\n',\n",
       "    '        import traceback\\n',\n",
       "    '        traceback.print_exc()\\n',\n",
       "    'else:\\n',\n",
       "    '    print(\"❌ Cannot generate ROC curves - no evaluation results\")']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'id': 'precision-recall-curves',\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Generate Precision-Recall curves\\n',\n",
       "    \"if 'eval_results' in locals() and eval_results is not None:\\n\",\n",
       "    '    print(\"Generating Precision-Recall curves...\")\\n',\n",
       "    '    \\n',\n",
       "    '    try:\\n',\n",
       "    '        evaluator.plot_precision_recall_curves(\\n',\n",
       "    \"            eval_results['y_true_classes'],\\n\",\n",
       "    \"            eval_results['y_pred'],\\n\",\n",
       "    \"            save_path=os.path.join(PLOTS_DIR, 'precision_recall_curves.png')\\n\",\n",
       "    '        )\\n',\n",
       "    '        print(\"✓ Precision-Recall curves generated\")\\n',\n",
       "    '        \\n',\n",
       "    '    except Exception as e:\\n',\n",
       "    '        print(f\"❌ Precision-Recall curves generation failed: {e}\")\\n',\n",
       "    '        import traceback\\n',\n",
       "    '        traceback.print_exc()\\n',\n",
       "    'else:\\n',\n",
       "    '    print(\"❌ Cannot generate Precision-Recall curves - no evaluation results\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'id': 'hyperparameter-tuning-header',\n",
       "   'metadata': {},\n",
       "   'source': ['## 3. Hyperparameter Tuning Analysis']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'id': 'hyperparameter-tuner-init',\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Initialize hyperparameter tuner\\n',\n",
       "    'print(\"Initializing hyperparameter tuner...\")\\n',\n",
       "    '\\n',\n",
       "    'try:\\n',\n",
       "    '    tuner = HyperparameterTuner()\\n',\n",
       "    '    \\n',\n",
       "    '    # Load data for tuning\\n',\n",
       "    '    if not tuner.trainer.load_data():\\n',\n",
       "    '        print(\"Using current preprocessor data...\")\\n',\n",
       "    '        tuner.trainer.preprocessor = preprocessor\\n',\n",
       "    '    \\n',\n",
       "    '    print(\"✓ Hyperparameter tuner initialized\")\\n',\n",
       "    '    \\n',\n",
       "    'except Exception as e:\\n',\n",
       "    '    print(f\"❌ Tuner initialization failed: {e}\")\\n',\n",
       "    '    import traceback\\n',\n",
       "    '    traceback.print_exc()']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'id': 'batch-size-analysis',\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Analyze batch size effect (with reduced epochs for notebook)\\n',\n",
       "    \"if 'tuner' in locals():\\n\",\n",
       "    '    print(\"Analyzing batch size effect...\")\\n',\n",
       "    '    print(\"(Using reduced epochs for notebook demonstration)\")\\n',\n",
       "    '    print(\"-\" * 45)\\n',\n",
       "    '    \\n',\n",
       "    '    try:\\n',\n",
       "    '        # Temporarily modify epochs for faster notebook execution\\n',\n",
       "    \"        original_epochs = tuner.trainer.epochs if hasattr(tuner.trainer, 'epochs') else 10\\n\",\n",
       "    '        \\n',\n",
       "    '        batch_results = tuner.analyze_batch_size_effect(\\n',\n",
       "    '            batch_sizes=[16, 32, 64], \\n',\n",
       "    '            epochs=5  # Reduced for notebook\\n',\n",
       "    '        )\\n',\n",
       "    '        \\n',\n",
       "    '        if batch_results:\\n',\n",
       "    '            # Convert to DataFrame for better visualization\\n',\n",
       "    '            batch_df = pd.DataFrame(batch_results)\\n',\n",
       "    '            print(\"\\\\nBatch Size Analysis Results:\")\\n',\n",
       "    \"            print(batch_df[['batch_size', 'final_val_accuracy', 'training_time']].round(4))\\n\",\n",
       "    '            \\n',\n",
       "    '            # Visualize results\\n',\n",
       "    '            try:\\n',\n",
       "    '                visualizer.plot_hyperparameter_analysis(\\n',\n",
       "    '                    batch_results, \\n',\n",
       "    \"                    'batch_size',\\n\",\n",
       "    \"                    save_path=os.path.join(PLOTS_DIR, 'batch_size_analysis.png')\\n\",\n",
       "    '                )\\n',\n",
       "    '                print(\"✓ Batch size analysis visualization completed\")\\n',\n",
       "    '            except Exception as viz_e:\\n',\n",
       "    '                print(f\"Visualization failed: {viz_e}\")\\n',\n",
       "    '                \\n',\n",
       "    '        else:\\n',\n",
       "    '            print(\"❌ Batch size analysis returned no results\")\\n',\n",
       "    '            \\n',\n",
       "    '    except Exception as e:\\n',\n",
       "    '        print(f\"❌ Batch size analysis failed: {e}\")\\n',\n",
       "    '        import traceback\\n',\n",
       "    '        traceback.print_exc()\\n',\n",
       "    'else:\\n',\n",
       "    '    print(\"❌ Cannot run batch size analysis - tuner not initialized\")']}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "source": "",
   "id": "dd07d5f345916d9a",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
